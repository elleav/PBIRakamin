# -*- coding: utf-8 -*-
"""Loan Prediction

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_DmfUxr8kqLuHydtLlC_PoxopKSaxRco
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import math
import dask.dataframe as dd
from matplotlib import rcParams

"""# Load Data

---


"""

from google.colab import drive
drive.mount('/content/drive')
loan = pd.read_csv('/content/drive/My Drive/loan_data_2007_2014.csv')
loan

#count issue_d from loan
loan['issue_d'].value_counts()

"""# Data Understanding"""

loan.info()

#Check missing values on loan and show all columns
missing_values = loan.isnull().sum()
missing_values = missing_values[missing_values > 0]
print(missing_values)

#Check duplicated data
loan.duplicated().sum()

"""# Data Cleansing

Ubah data loan menjadi loan_data untuk antisipasi runtime dan kehilangan data
"""

loan_data = loan
loan_data.info()

"""Kolom yang tidak ada data sudah dipastikan tidak dipakai untuk perhitungan model, jadi dihapus saja"""

#Delete Column with 0 non-null in loan
loan_data = loan.dropna(axis=1, how='all')
loan_data.info()

"""Kolom yang memiliki banyak identifiers juga akan membuat sulit perhitungan korelasi sehingga lebih baik dihapus, namun ada Zip Code yang mempunyai pattern tersendiri sehingga nanti Zip Code dibiarkan untuk di analisa dulu di EDA"""

#Delete Columns with unique identifiers data
loan_data = loan_data.drop(['id', 'member_id', 'url', 'desc', 'title', 'Unnamed: 0'], axis=1)
loan_data.info()

"""Kolom yang memiliki 1 jenis kategori juga dihapus agar lebih efisien dalam perhitungan model"""

#Check column with unique identifiers data
unique_values = loan_data.nunique()
unique_values[unique_values == 1]

# Find columns with only one unique value
unique_value_counts = loan_data.nunique()
columns_to_drop = unique_value_counts[unique_value_counts == 1].index

# Drop these columns from the DataFrame
loan_data = loan_data.drop(columns=columns_to_drop)

loan_data.info()

"""Beberapa kolom data ada yang salah tipe data nya sehingga di convert dulu agar lebih mudah dalam mengkategorikan data category dan data numerical"""

#Change date column type
loan_data['issue_d'] = pd.to_datetime(loan_data['issue_d'], format='%b-%y', errors='coerce')
loan_data['earliest_cr_line'] = pd.to_datetime(loan_data['earliest_cr_line'], format='%b-%y', errors='coerce')
loan_data['last_pymnt_d'] = pd.to_datetime(loan_data['last_pymnt_d'], format='%b-%y', errors='coerce')
loan_data['last_credit_pull_d'] = pd.to_datetime(loan_data['last_credit_pull_d'], format='%b-%y', errors='coerce')
loan_data['next_pymnt_d'] = pd.to_datetime(loan_data['next_pymnt_d'], format='%b-%y', errors='coerce')

#Clear the last two digits from zip_code column and change the type to string
loan_data['zip_code'] = loan_data['zip_code'].apply(lambda x: x[:-2] if isinstance(x, str) else x)

#Convert zip_code to string
loan_data['zip_code'] = loan_data['zip_code'].astype(str)

loan_data.info()

"""Memastikan kembali adakah kolom yang 50% isinya kosong, dan lebih baik dihapus agar tetap mempertahankan keaslian data"""





# Calculate the percentage of missing values per column
# Exclude columns with datetime data type
non_date_columns = loan_data.select_dtypes(exclude=['datetime']).columns

# Calculate the percentage of missing values for non-date columns
missing_percentage = loan_data[non_date_columns].isnull().mean()

# Identify columns with more than 50% missing values
columns_to_check = missing_percentage[missing_percentage > 0.5]

# Display columns with their missing value percentages
print("Columns with more than 50% missing values:")
print(columns_to_check)

#Delete columns_to_check in loan_data
loan_data = loan_data.drop(columns=columns_to_check.index)

"""Cek kembali melalui info dan describe"""

loan_data.info()

loan_data.describe()

"""Agar analisa lebih tajam saat EDA, langsung dibuat Target nasabah yang memiliki riwayat pinjaman yang baik (dengan nilai 1) dan yang buruk (dengan nilai 0) berdasarkan loan_status dan di cek berdasarkan riwayat waktu pinjaman"""

#Check unique values in loan_status and group by terms
pd.set_option('display.max_colwidth', None)
loan_data.groupby('term')['loan_status'].unique()

"""Penjelasan status-status dalam loan_status dan diurutkan berdasarkan waktu pinjaman:
1. Current
- Artinya:
Pinjaman masih sedang berlangsung
- Konteks:
Peminjam membayar pinjaman tepat waktu dan tidak ada pembayaran yang terlewat.

2. Fully Paid
- Artinya:
Pinjaman ini sudah dibayar lunas oleh peminjam sesuai dengan jadwal yang disepakati.
- Konteks:
Tidak ada masalah dengan pembayaran, dan pinjaman ini dianggap berhasil dilunasi sepenuhnya tanpa keterlambatan atau masalah lainnya.


3. In Grace Period
- Artinya:
Pinjaman masih dalam periode tenggang, yang artinya peminjam memiliki tambahan waktu untuk melakukan pembayaran tanpa dikenakan penalti lebih lanjut.
- Konteks:
Biasanya terjadi setelah peminjam terlambat beberapa hari, dan pemberi pinjaman memberikan kelonggaran waktu tambahan untuk membayar sebelum statusnya berubah menjadi "late."


4. Late (16-30 days)
- Artinya:
Pinjaman terlambat antara 16 hingga 30 hari.
- Konteks:
Pinjaman berada dalam periode keterlambatan yang relatif singkat, dan peminjam mungkin dikenakan biaya keterlambatan atau peringatan.

5. Late (31-120 days)
- Artinya:
Pinjaman terlambat pembayaran antara 31 hingga 120 hari.
- Konteks:
Peminjam belum membayar sesuai jadwal, tetapi belum cukup lama untuk dianggap sebagai "charged off."
Dampak bagi peminjam:
Terlambat dalam pembayaran akan mempengaruhi skor kredit, dan peminjam mungkin dikenakan biaya keterlambatan.
Pemberi pinjaman mungkin mulai melakukan upaya untuk menagih pembayaran.

6. Charged Off
- Artinya:
Pinjaman ini dianggap tidak dapat ditagih lagi oleh pemberi pinjaman karena peminjam tidak dapat atau tidak mau membayar dalam waktu yang lama.
- Konteks:
Biasanya terjadi setelah 60 hari keterlambatan pembayaran. Setelah periode ini, pemberi pinjaman biasanya menganggap pinjaman tersebut sebagai kerugian dan menulisnya dalam pembukuan mereka sebagai "charged off".

7. Default
- Artinya:
Pinjaman sudah gagal bayar total, sering kali karena peminjam tidak membayar dalam jangka waktu yang sangat lama.
- Konteks:
Peminjam tidak mampu atau tidak mau membayar sama sekali, dan pemberi pinjaman akhirnya menandai pinjaman tersebut sebagai gagal bayar.
Dampak bagi peminjam:
Seringkali mengarah pada penagihan oleh kolektor utang.
Peminjam akan kesulitan untuk mendapatkan pinjaman baru dengan lembaga pemberi pinjaman mana pun, dan skor kredit mereka akan turun secara signifikan

8. Does not meet the credit policy. Status: Fully Paid
- Artinya:
Pinjaman diberikan meskipun tidak memenuhi kebijakan kredit yang berlaku. Dengan kata lain, pinjaman ini diberikan kepada peminjam yang tidak memenuhi seluruh kriteria yang biasanya ditetapkan oleh lembaga pemberi pinjaman, misalnya skor kredit yang rendah atau pendapatan yang tidak cukup.
Namun, pinjaman ini pada akhirnya dibayar lunas oleh peminjam.
- Konteks dan Penyebab:
Keputusan manual atau pengecualian: Meskipun tidak memenuhi syarat secara otomatis menurut kebijakan standar (misalnya karena masalah pada skor kredit atau penghasilan), pemberi pinjaman mungkin membuat pengecualian berdasarkan alasan tertentu (misalnya, alasan pribadi atau jaminan lainnya).
Perubahan kebijakan kredit: Pemberi pinjaman bisa jadi memperbarui kebijakan kredit mereka untuk memberikan pinjaman kepada lebih banyak orang, meskipun sebelumnya tidak memenuhi kriteria.
Pinjaman disetujui dengan pertimbangan risiko: Misalnya, jika peminjam menunjukkan potensi pendapatan yang akan datang atau memiliki jaminan yang sangat kuat, pinjaman tetap diberikan meskipun ada kekurangan dalam evaluasi standar.
Dampak bagi peminjam:
Peminjam ini mampu melunasi pinjaman meskipun dalam kondisi awal dianggap berisiko.
Pinjaman ini tidak menciptakan masalah di masa depan karena berhasil dibayar penuh.
Pemberi pinjaman bisa mencatatnya sebagai pinjaman yang berisiko lebih tinggi karena diluar kebijakan kredit, meskipun berhasil dilunasi.

9. Does not meet the credit policy. Status: Charged Off
- Artinya:
Pinjaman tidak memenuhi kebijakan kredit yang berlaku pada awalnya.
Pinjaman ini dianggap gagal bayar dan kemudian ditulis sebagai "charged off" oleh pemberi pinjaman. Artinya, pemberi pinjaman sudah menyerah untuk mencoba menagih pinjaman ini setelah gagal bayar dalam waktu yang lama (misalnya lebih dari 180 hari).
- Konteks dan Penyebab:
Tidak ada pembayaran atau sangat terlambat: Peminjam tidak dapat melunasi pinjaman meskipun sudah diberikan waktu tambahan. Pemberi pinjaman menganggap bahwa peminjam sudah tidak mampu membayar.
Pinjaman dianggap berisiko tinggi sejak awal: Kebijakan kredit yang tidak dipenuhi bisa jadi menunjukkan risiko yang lebih besar. Peminjam mungkin memiliki riwayat kredit yang buruk atau kondisi keuangan yang tidak stabil.
Sistem penagihan gagal atau diabaikan: Setelah beberapa bulan atau lebih, pemberi pinjaman mungkin merasa bahwa penagihan tidak efektif, dan akhirnya mencatat pinjaman ini sebagai kerugian dalam pembukuan mereka.

Ada kejanggalan pada status current, namun karena status peminjam masih berlangsung artinya bisa jadi peminjam dianggap memiliki status yg baik sehingga diberikan pinjaman lagi, atau peminjam baru berlangsung 1x pinjaman, oleh karena itu current akan tidak dikategorikan kedalam perhitungan dulu

sehingga nasaabah dianggap memiliki kredibilitas yang baik jika melewati tahap 2,3,4,9
"""

#Make new column to categorize the good credibility without applying 'current' category
loan_data['credible'] = loan_data['loan_status'].apply(
    lambda x: 1 if x in ['Fully Paid', 'In Grace Period', 'Does not meet the credit policy. Status:Fully Paid', 'Late (16-30 days)']
    else (0 if x in ['Charged Off', 'Late (31-120 days)', 'Default', 'Does not meet the credit policy. Status:Charged Off'] else None)
)

loan_data.head()

credible_counts = loan_data['credible'].value_counts()

#Count loan status group by credible
loan_data.groupby('credible')['loan_status'].value_counts()

credible_counts

#Check categorical and numerical columns and find if there are some miss
cats = loan_data.select_dtypes(include=['object']).columns
nums = loan_data.select_dtypes(include=['int64', 'float64']).columns

print("Categorical columns:", cats)
print("Numerical columns:", nums)

"""Ternyata term dan emp_length dianggap kategorikal padahal harusnya numerikal, maka diubah dulu"""

# Remove the word 'months' and convert to numerical format
loan_data['term'] = loan_data['term'].str.replace(' months', '').astype(int)

# Define a mapping for emp_length categories to numerical values
emp_length_mapping = {
    '< 1 year': 0,
    '1 year': 1,
    '2 years': 2,
    '3 years': 3,
    '4 years': 4,
    '5 years': 5,
    '6 years': 6,
    '7 years': 7,
    '8 years': 8,
    '9 years': 9,
    '10+ years': 10
}

# Apply the mapping to the 'emp_length' column
loan_data['emp_length'] = loan_data['emp_length'].replace(emp_length_mapping)

# Display the updated DataFrame
loan_data.head()

#Re-check categorical and numerical columns
cats = loan_data.select_dtypes(include=['object']).columns
nums = loan_data.select_dtypes(include=['int64', 'float64']).columns

print("Categorical columns:", cats)
print("Numerical columns:", nums)

loan_data.isnull().sum()

#Export loan_data to csv
loan_data.to_csv('loan_data.csv', index=False)

loan_data

"""# Insight and Recommendation

## Univariate Analysis pada tiap Fitur Kategorikal dan Numerikal
"""

import pandas as pd

# Univariate Analysis on categorical columns and display as tables
for col in cats:
    value_counts_df = pd.DataFrame(loan_data[col].value_counts()).reset_index()
    value_counts_df.columns = [col, 'Count']  # Rename columns for better readability
    print(f'Value Count Table for Column: {col}')
    print(value_counts_df)
    print()



import pandas as pd
import plotly.express as px

purpose_data = loan_data['purpose'].value_counts().reset_index()
purpose_data.columns = ['purpose', 'count']

# Create a DataFrame for the bar plot
df = pd.DataFrame(purpose_data)


# Create the bar plot
fig = px.bar(
    df,
    x='purpose',
    y='count',
    text='count',  # Display counts on bars
    title='Distribution of Loan Purposes',
    labels={'purpose': 'Purpose of Loan', 'count': 'Number of Loans'},
    color='count',  # Use a gradient color scheme
    color_continuous_scale='Viridis'  # Choose a visually appealing color scale
)

# Customize aesthetics
fig.update_layout(
    title_font_size=20,
    title_font_family='Arial',
    xaxis_title='Purpose of Loan',
    yaxis_title='Number of Loans',
    xaxis_tickangle=-45,  # Tilt x-axis labels for readability
    template='plotly_white',  # Use a clean background template
    margin=dict(l=40, r=40, t=60, b=120),  # Adjust margins
    showlegend=False  # Hide legend for a single category
)

# Add hover labels and adjust text size
fig.update_traces(
    textposition='outside',
    textfont_size=12,
    hovertemplate='<b>%{x}</b><br>Count: %{y}<extra></extra>'
)

# Show the plot
fig.show()

"""Untuk melihat karakteristik peminjam, kita lihat dari tujuannya. Debt consolidation dan credit card menonjol, menandakan bahwa mayoritas pinjaman digunakan untuk pengelolaan hutang pribadi. Segmen seperti energi terbarukan dan pendidikan memiliki potensi untuk berkembang, terutama jika diberikan insentif atau program khusus."""

import pandas as pd
import plotly.express as px

# Get value counts for 'addr_state' and reset index
state_data = loan_data['addr_state'].value_counts().reset_index()
state_data.columns = ['addr_state', 'count']

# Take the top 10 states only
top_state_data = state_data.nlargest(10, 'count')

# Create a DataFrame for the bar plot
df = pd.DataFrame(top_state_data)

# Create the bar plot
fig = px.bar(
    df,
    x='addr_state',
    y='count',
    text='count',  # Display counts on bars
    title='Top 10 States by Number of Loan Applicants',
    labels={'addr_state': 'State', 'count': 'Number of Loans'},
    color='count',  # Use a gradient color scheme
    color_continuous_scale='Plasma'  # Choose a new color scale
)

# Customize aesthetics
fig.update_layout(
    title_font_size=20,
    title_font_family='Arial',
    xaxis_title='State',
    yaxis_title='Number of Loans',
    xaxis_tickangle=-45,  # Tilt x-axis labels for readability
    template='plotly_white',  # Use a clean background template
    margin=dict(l=40, r=40, t=60, b=120),  # Adjust margins
    showlegend=False  # Hide legend for a single category
)

# Add hover labels and adjust text size
fig.update_traces(
    textposition='outside',
    textfont_size=12,
    hovertemplate='<b>%{x}</b><br>Count: %{y}<extra></extra>'
)

# Show the plot
fig.show()

"""California (CA) memiliki jumlah peminjam tertinggi (71.450), jauh melebihi negara bagian lainnya. Setelah California, New York (NY) dan Texas (TX) menempati posisi kedua dan ketiga dengan masing-masing 40.242 dan 36.439 peminjam. Ini menunjukkan potensi pasar yang cukup besar di kedua negara bagian tersebut, meskipun masih jauh di bawah California."""



import matplotlib.pyplot as plt
import seaborn as sns

# Univariate Analysis on numerical columns and display as tables
# Calculate the number of rows and columns needed for the subplots
num_plots = len(nums)
num_cols = 3  # Number of columns in the grid
num_rows = (num_plots + num_cols - 1) // num_cols  # Calculate number of rows

# Create the subplots with adjusted grid layout
fig, axes = plt.subplots(num_rows, num_cols, figsize=(20, 5 * num_rows))  # Adjust figsize as needed

# Flatten the axes array if necessary
axes = axes.flatten()

# Iterate through the numerical columns and create box plots
for i, num_col in enumerate(nums):
    sns.boxplot(y=loan_data[num_col], color='green', orient='v', ax=axes[i])
    axes[i].set_title(num_col)

# Hide any unused subplots
for i in range(num_plots, num_rows * num_cols):
    axes[i].set_visible(False)

plt.tight_layout()
plt.show()

"""## Univariate Analysis pada nasabah yang layak dan tidak layak

Analisa jumlah nasabah yang layak dan tidak layak
"""

import matplotlib.pyplot as plt

# Calculate value counts for the binary 'credible' column
credible_counts = loan_data['credible'].value_counts()

# Labels for the pie chart
labels = ['Credible', 'Not Credible']

# Define a function to display percentages and counts
def make_autopct(values):
    def my_autopct(pct):
        total = sum(values)
        count = int(round(pct * total / 100.0))  # Calculate count
        return f'{pct:.1f}%\n({count})'         # Format percentage and count
    return my_autopct

# Create a pie chart
plt.figure(figsize=(6, 6))
plt.pie(
    credible_counts,
    labels=labels,
    autopct=make_autopct(credible_counts),  # Use the custom function
    startangle=90,                         # Rotate the start of the pie chart
    colors=['salmon', 'lightblue'],        # Custom colors
    explode=(0, 0.1)                       # Slightly separate the 'Credible' slice
)

# Add title
plt.title('Distribution of Credible Customers')

# Show the plot
plt.show()

"""Interpretasi:

Ternyata sebanyak hampir 21% nasabah banyak yang dianggap tidak layak sebanyak 50.968 data. Sedangkan 78.9% atau sekitar 191.091 nasabah dianggap layak diberikan pinjaman

Artinya distribusi data skewed dan perlu dilakukan class imbalance agar tidak bias dengan penilaian layak pada model

Rekomendasi:
Perlu diturunkan  porsi nasabah tidak layak menjadi lebih kecil dari 21% dengan Meminimalkan kemungkinan gagal bayar (default) dengan strategi plafon pinjaman
- Batasi jumlah pinjaman awal untuk nasabah baru dengan profil risiko menengah hingga tinggi
- Naikkan plafon pinjaman secara bertahap berdasarkan rekam jejak pembayaran
- Sediakan pinjaman mikro dengan plafon rendah dan tenor pendek sebagai “uji kelayakan” bagi nasabah dengan risiko tinggi

Sehingga dapat mengurangi beban awal nasabah, sehingga lebih mudah membayar tepat waktu sekaligus membangun track record kredit positif.

## Bivariate Analysis Kelayakan Nasabah dengan Kategori

Top 10 Profesi dengan kelayakan hutang yang baik (1) dan yang kurang baik (0)
"""

#Make plot of Top 10 Profession group by 1 and 0 from Credible

# Group by emp_title and credible status, then count
emp_title_counts = loan_data.groupby(['emp_title', 'credible']).size().reset_index(name='count')

# Filter for credible = 1 and get top 10 emp_titles
top_10_credible = (
    emp_title_counts[emp_title_counts['credible'] == 1]
    .sort_values(by='count', ascending=False)
    .head(10)
)

# Filter for credible = 0 and get top 10 emp_titles
top_10_non_credible = (
    emp_title_counts[emp_title_counts['credible'] == 0]
    .sort_values(by='count', ascending=False)
    .head(10)
)

# Display results
print("Top 10 Emp Titles with  Credible = 1:")
print(top_10_credible)

print("\nTop 10 Emp Titles with Not Credible = 0:")
print(top_10_non_credible)

import seaborn as sns
import matplotlib.pyplot as plt

# Filter top 10 credible and non-credible employee titles
top_10_credible = (
    emp_title_counts[emp_title_counts['credible'] == 1]
    .sort_values(by='count', ascending=False)
    .head(10)
)
top_10_non_credible = (
    emp_title_counts[emp_title_counts['credible'] == 0]
    .sort_values(by='count', ascending=False)
    .head(10)
)

# Create bar chart for credible = 1
plt.figure(figsize=(12, 6))
sns.barplot(
    data=top_10_credible,
    x='count',
    y='emp_title',
    palette='Blues_d'
)
plt.title('Top 10 Employee Titles with Credible = 1', fontsize=16)
plt.xlabel('Count', fontsize=12)
plt.ylabel('Employee Title', fontsize=12)
plt.tight_layout()
plt.show()

# Create bar chart for credible = 0
plt.figure(figsize=(12, 6))
sns.barplot(
    data=top_10_non_credible,
    x='count',
    y='emp_title',
    palette='Reds_d'
)
plt.title('Top 10 Employee Titles with Not Credible = 0', fontsize=16)
plt.xlabel('Count', fontsize=12)
plt.ylabel('Employee Title', fontsize=12)
plt.tight_layout()
plt.show()

"""Interpretasi:
Dominasi Profesi:

Profesi seperti Guru (1,306), Manager (1,221), dan Perawat terdaftar (1,119 jika digabungkan) memiliki jumlah terbesar dalam kategori credible loans (credible = 1).
Profesi ini cenderung stabil dan memiliki penghasilan tetap yang memungkinkan mereka untuk membayar kembali pinjaman dengan baik.

Pekerjaan seperti Tentara (384) juga menunjukkan kepercayaan pada stabilitas keuangan karena keamanan pekerjaan yang relatif tinggi dalam sektor publik.

Profesi seperti Manager, Teacher, dan Supervisor juga muncul dalam daftar tidak laya tetapi dengan jumlah lebih rendah, menunjukkan bahwa beberapa individu dalam profesi ini menghadapi kesulitan membayar pinjaman

Pekerjaan seperti Driver (268 jika digabungkan) dan Owner (116) juga memiliki tingkat ketidakmampuan yang lebih tinggi dalam membayar pinjaman. Ini mungkin karena sifat pekerjaan yang kurang stabil atau bergantung pada penghasilan tidak tetap.


Rekomendasi:
Dapat dipertimbangkan risk assessment berbasis profesi. Profesi dengan tingkat kredibilitas tinggi seperti Teacher, Registered Nurse, dan Supervisor dapat diberikan penawaran pinjaman yang lebih menarik (misalnya, suku bunga lebih rendah).


"""



"""Pengaruh home ownership  dengan kelayakan hutang yang baik (1) dan yang kurang baik (0)"""

import plotly.express as px

# Filter data to include only credible = 1 and credible = 0, and exclude unwanted values
home_ownership_counts = (
    loan_data[(loan_data['credible'].isin([1, 0])) &
              (loan_data['home_ownership'].notnull()) &
              (~loan_data['home_ownership'].isin(['Any', 'None', 'Other']))]
    .groupby(['home_ownership', 'credible'])
    .size()
    .reset_index(name='count')
)

# Create an interactive bar chart using Plotly
fig = px.bar(
    home_ownership_counts,
    x='home_ownership',
    y='count',
    color='credible',
    barmode='group',
    title='Loan Counts by Home Ownership with Credible Status (1 vs 0)',
    labels={'count': 'Count', 'home_ownership': 'Home Ownership'},
    color_discrete_map={1: 'green', 0: 'red'}  # Custom color map for credibility
)

# Update the chart layout for better aesthetics
fig.update_layout(
    xaxis_tickangle=-45,  # Rotate x-axis labels for better readability
    template='plotly_white',  # Use a clean, white background template
    xaxis_title='Home Ownership',
    yaxis_title='Count'
)

# Show the chart
fig.show()

"""Interpretasi:

Sebagian besar data menunjukkan jumlah yang lebih tinggi untuk kategori credible (1) pada jenis kepemilikan rumah ANY, MORTGAGE, dan RENT.
Kategori NONE dan OTHER menunjukkan jumlah yang lebih rendah, dengan kategori OWN memiliki jumlah nasabah yang layak lebih sedikit dibandingkan kategori lainnya.

Besar Bunga dan Jumlah hutang pada nasabah
"""

# Average 'term', 'int_rate', and 'loan_amnt' and grouped them from credible
loan_data.groupby('credible')[['term', 'int_rate', 'loan_amnt']].mean()

"""Interpretasi:
- Term (Jangka Waktu): Nasabah tidak layak rata-rata memiliki jangka waktu pinjaman lebih lama (44.55 bulan) dibandingkan yang layak (40.45 bulan).
- Interest Rate (Tingkat Bunga): Nasabah tidak layak dikenakan bunga rata-rata lebih tinggi (15.97%) dibandingkan nasabah layak (13.32%).
- Loan Amount (Jumlah Pinjaman): Nasabah tidak layak meminjam rata-rata jumlah yang lebih besar (14,596.85) dibandingkan yang layak ($13,233.48).

Hal ini mengindikasikan bahwa nasabah yang mengajukan jumlah pinjaman dalam jangka waktu yang lama, memiliki bunga yang tinggi berpotensi risiko gagal bayar atau nasabah menjadi tidak layak diberikan pinjaman.

Rekomendasi:
- Revisi Kebijakan Pinjaman: Sesuaikan jumlah pinjaman dan jangka waktu untuk nasabah dengan kelayakan rendah.
- Penyesuaian Suku Bunga: Terapkan suku bunga yang lebih tinggi untuk nasabah berisiko dan lebih rendah untuk nasabah layak.
- Pengelolaan Risiko: Analisis faktor-faktor yang menyebabkan nasabah tidak layak memilih jumlah pinjaman besar untuk mengurangi risiko.
"""

import matplotlib.pyplot as plt

# Assuming 'loan_data' is your DataFrame
loan_data['issue_d'] = pd.to_datetime(loan_data['issue_d'], format='%b-%y')   # Convert 'issue_d' to datetime

# Group by year and credibility, and count the number of occurrences for each group
trend_data = loan_data.groupby([loan_data['issue_d'].dt.year, 'credible']).size().unstack(fill_value=0)

# Plot the trend as a line chart
trend_data.plot(kind='line', figsize=(14, 7), marker='o')

# Add labels and title
plt.xlabel('Year')
plt.ylabel('Number of Loans')
plt.title('Trend of Loans by Year for Credible and Not Credible Status')
plt.legend(title='Credible', labels=['Not Credible (0)', 'Credible (1)'])
plt.grid(True)

# Adjust y-axis for a more comprehensive view (e.g., use larger step intervals)
plt.yticks(range(0, trend_data.values.max() + 1, 10000))  # Adjust step (e.g., 10000) as needed
plt.show()

trend_data

"""Secara umum, jumlah pinjaman mengalami peningkatan signifikan dari tahun ke tahun, terutama pada kategori credible (1.0). Ini menunjukkan bahwa lebih banyak pinjaman disetujui dan dianggap layak seiring berjalannya waktu.

Sementara jumlah pinjaman credible meningkat, jumlah pinjaman dengan status not credible (0.0) juga mengalami peningkatan, tetapi tidak secepat jumlah credible. Jumlah pinjaman not credible meningkat dari 158 pada tahun 2007 menjadi 19,441 pada tahun 2014, yang menunjukkan adanya peningkatan risiko dalam periode tersebut.

Kondisi ekonomi di Amerika Serikat antara 2007-2014 menunjukkan adanya dampak besar dari krisis keuangan global yang menyebabkan banyak peminjam mengalami kesulitan finansial setelah puncak krisis pada tahun 2008-2009

## Bivariate Analysis pada resiko gagal bayar per category dengan credible (Target)
"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

cats_new = ['grade', 'sub_grade', 'home_ownership',
       'verification_status', 'pymnt_plan', 'purpose',
       'initial_list_status']

# Set up the figure
plt.figure(figsize=(20, 80))

# Loop through numerical columns to plot the risk of default
for i, col in enumerate(cats_new, 1):
    # Calculate risk of default (credible = 0) for each numerical value
    risk_default = loan_data.groupby(col)['credible'].value_counts(normalize=True).unstack(fill_value=0)[0] * 100

    # Plot the risk of default
    plt.subplot(7, 1, i)
    sns.lineplot(x=risk_default.index, y=risk_default.values, marker='o')
    plt.title(f'Risk of Default for {col}')
    plt.xlabel(col,  fontsize=20)
    plt.ylabel('Risk of Default (%)', fontsize=20)
    plt.xticks(fontsize=20, rotation=90)  # Set x-axis tick font size
    plt.yticks(fontsize=20)
    plt.grid(True)

plt.tight_layout()
plt.show()

"""## Multivariate Analysis faktor numerikal lain yang mempengaruhi status kelayakan nasabah"""

### CORRELATION WITH EACH FEATURES ###

loan_data.corr(numeric_only=True)

import seaborn as sns
import matplotlib.pyplot as plt

# Calculate correlation matrix
loan_corr = loan_data.corr(numeric_only=True)  # or use df_europe.select_dtypes(include=['number']).corr()

# Set up the figure size and aesthetic
plt.figure(figsize=(50, 30))
sns.set_theme(style="whitegrid")

# Create a heatmap
heatmap = sns.heatmap(loan_corr, annot=True, cmap='coolwarm', linewidths=0.5, vmin=-1, vmax=1,  annot_kws={"size": 20})

# Add title
plt.title('Correlation Heatmap for Loan Data Features', fontsize=40)

# Display the plot
plt.show()

"""# Additional Data Cleansing"""

loan_clean = loan_data.copy()

loan_clean.info()

"""Setelah di lakukan EDA, kolom yang tidak relevan untuk dijadikan fitur sebaiknya dihapus dengan kategori
- Banyak unique values (emp_title dan emp_length)
- Similiaritas dengan kolom lain (sub-grade)
- Tanggal dan waktu yang tidak berkaitan, karena model yang akan di bangun tidak bergantung pada waktu (issue_d, last_pymnt_d, last_credit_pull_d, next_pymnt_d)
- didominasi oleh 1 data (pymnt_plan)


"""

#Remove unecessary column
loan_clean = loan_clean.drop(['emp_title', 'emp_length', 'sub_grade', 'issue_d', 'earliest_cr_line', 'last_pymnt_d','pymnt_plan', 'last_credit_pull_d', 'next_pymnt_d'], axis=1)

"""Membuang fitur yang redundan"""

#Find columns with correlation above 0.7 Except total_pymnt and last_pymnt_amnt

corr_matrix = loan_data.corr(numeric_only=True).abs()
upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))
to_drop = [column for column in upper.columns if any(upper[column] > 0.7)]


print("Columns to be dropped based on correlation:")
print(to_drop)

#Drop the highly corelated columns excluce total_pymnt and last_pymnt_amnt
to_drop = [column for column in upper.columns if any(upper[column] > 0.7) and column not in ['total_pymnt', 'last_pymnt_amnt']]
loan_clean = loan_clean.drop(to_drop, axis=1)

loan_clean.info()

"""# Handling Missing Values"""

#Count missing values each columns
loan_clean.isnull().sum()

"""Baris yang mengandung missing value berlebih dihapus untuk tetap mempertahankan keaslian data"""

#Delete Excessive Rows Values
loans = loan_clean.dropna()

loans.info()

#Import data to csv
loans_bo = loans.copy()
loans_bo.to_csv('loans_bo.csv', index=False)

# Set display options to show all columns
pd.set_option('display.max_columns', None)

#count pub_rec
loans['pub_rec'].value_counts()

"""# Handling Outliers"""



"""Outliers di biarkan saja karena kebanyakan data numerikal berbentuk angka yang pilihan kategori"""

#Create numerical from int64 and float
nums = loans.select_dtypes(include=['int64', 'float64']).columns.tolist()

# Univariate Analysis on numerical columns and display as tables
# Calculate the number of rows and columns needed for the subplots
num_plots = len(nums)
num_cols = 3  # Number of columns in the grid
num_rows = (num_plots + num_cols - 1) // num_cols  # Calculate number of rows

# Create the subplots with adjusted grid layout
fig, axes = plt.subplots(num_rows, num_cols, figsize=(15, 5 * num_rows))  # Adjust figsize as needed

# Flatten the axes array if necessary
axes = axes.flatten()

# Iterate through the numerical columns and create box plots
for i, num_col in enumerate(nums):
    sns.boxplot(y=loans[num_col], color='green', orient='v', ax=axes[i])
    axes[i].set_title(num_col)

# Hide any unused subplots
for i in range(num_plots, num_rows * num_cols):
    axes[i].set_visible(False)

plt.tight_layout()
plt.show()



# Print value of rows after outlier handling
loans.info()

"""### Drop duplicates"""

loan_duplicates = len(loan_data)-len(loan_data.drop_duplicates())
print('total duplicates data =', loan_duplicates)

"""# Cek ulang korelasi antar fitur dan target"""

import seaborn as sns
import matplotlib.pyplot as plt

# Calculate correlation matrix
loans_corr = loans.corr(numeric_only=True)  # or use df_europe.select_dtypes(include=['number']).corr()

# Set up the figure size and aesthetic
plt.figure(figsize=(50, 30))
sns.set_theme(style="whitegrid")

# Create a heatmap
heatmap = sns.heatmap(loans_corr, annot=True, cmap='coolwarm', linewidths=0.5, vmin=-1, vmax=1,  annot_kws={"size": 20})

# Add title
plt.title('Correlation Heatmap for Loans Features', fontsize=40)

# Display the plot
plt.show()

#import loans to csv
loans.to_csv('loans.csv', index=False)